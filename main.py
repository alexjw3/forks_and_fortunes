"""
Main execution script for Forks & Fortunes analysis

This script orchestrates the complete analysis pipeline:
1. Data collection (Census, Zillow, Restaurant data)
2. Data merging and processing
3. Analysis and visualization
4. Report generation
"""

import os
import sys
import argparse
import pandas as pd
import logging
from datetime import datetime

from config import Config
from data_collector import DataCollector
from restaurant_analyzer import RestaurantAnalyzer
from analysis_utils import AnalysisUtils

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('forks_fortunes.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


def main(mode='full', wealth_tier=None):
    """Main execution function"""
    logger.info("ğŸ´ğŸ’° Starting Forks & Fortunes Analysis")
    logger.info("=" * 60)
    
    # Create directories
    Config.create_directories()
    
    # Initialize components
    data_collector = DataCollector()
    restaurant_analyzer = RestaurantAnalyzer()
    analysis_utils = AnalysisUtils()
    
    # Determine cities to analyze based on mode
    if mode == 'test':
        cities_to_analyze = Config.TEST_CITIES
        logger.info(f"ğŸ§ª Running in TEST mode with {len(cities_to_analyze)} cities")
    elif mode == 'tier' and wealth_tier:
        cities_to_analyze = Config.WEALTH_TIERS.get(wealth_tier, Config.CITIES_TO_ANALYZE)
        logger.info(f"ğŸ’° Analyzing {wealth_tier} tier: {len(cities_to_analyze)} cities")
    else:
        cities_to_analyze = Config.CITIES_TO_ANALYZE
        logger.info(f"ğŸ™ï¸ Running FULL analysis with {len(cities_to_analyze)} cities")
    
    logger.info(f"Cities to analyze: {', '.join(cities_to_analyze)}")
    
    try:
        # Step 1: Census Data Collection
        logger.info("\nğŸ“Š STEP 1: Census Data Collection")
        logger.info("-" * 40)
        
        # Try to load existing census data first
        census_df = data_collector.load_existing_census_data()
        if census_df is None:
            logger.info("No existing census data found. Collecting from API...")
            census_df = data_collector.collect_census_data()
            data_collector.save_census_data(census_df)
        else:
            logger.info(f"Using existing census data with {len(census_df)} ZIP codes")
        
        # Step 2: Zillow Data Loading
        logger.info("\nğŸ  STEP 2: Zillow Data Loading")
        logger.info("-" * 40)
        
        zillow_df = data_collector.load_zillow_data(Config.ZILLOW_FILE)
        if zillow_df.empty:
            logger.error("âŒ Could not load Zillow data. Please check the file path.")
            return
        
        # Step 3: Restaurant Data Analysis with Quality Metrics
        logger.info("\nğŸ½ï¸â­ STEP 3: Restaurant Data Analysis with Quality Metrics")
        logger.info("-" * 40)
        
        # Check if we should use existing quality restaurant data or analyze selected cities
        existing_quality_file = f"{Config.RESULTS_DIR}/restaurant_quality_results.csv"
        
        # Load existing data and check if we need to analyze additional cities
        existing_restaurant_df = None
        cities_already_analyzed = []
        
        if os.path.exists(existing_quality_file):
            logger.info("Found existing restaurant quality data. Loading...")
            existing_restaurant_df = pd.read_csv(existing_quality_file)
            cities_already_analyzed = existing_restaurant_df['City'].unique().tolist()
            logger.info(f"Already have data for {len(cities_already_analyzed)} cities: {cities_already_analyzed}")
        
        # Determine which cities still need analysis
        cities_to_analyze_new = [city for city in cities_to_analyze if city not in cities_already_analyzed]
        
        if cities_to_analyze_new:
            logger.info(f"Need to analyze {len(cities_to_analyze_new)} new cities: {cities_to_analyze_new}")
            logger.warning("âš ï¸ This will take a while due to API rate limits...")
            
            # Analyze the new cities
            new_restaurant_df = restaurant_analyzer.analyze_cities_with_quality(cities_to_analyze_new)
            
            # Combine with existing data if available
            if existing_restaurant_df is not None:
                restaurant_df = pd.concat([existing_restaurant_df, new_restaurant_df], ignore_index=True)
                logger.info(f"Combined existing data with new analysis: {len(restaurant_df)} total cities")
            else:
                restaurant_df = new_restaurant_df
            
            # Save the updated dataset
            restaurant_analyzer.save_restaurant_results(restaurant_df, "restaurant_quality_results.csv")
            
        elif existing_restaurant_df is not None:
            # Filter existing data to only include cities we want to analyze
            restaurant_df = existing_restaurant_df[existing_restaurant_df['City'].isin(cities_to_analyze)].copy()
            logger.info(f"Using existing data for {len(restaurant_df)} cities (filtered to selected cities)")
            
        else:
            logger.error("No existing data and no cities to analyze!")
            return
        
        # Step 4: Data Merging and Analysis
        logger.info("\nğŸ”— STEP 4: Data Merging and Analysis")
        logger.info("-" * 40)
        
        # Merge all datasets
        merged_df = analysis_utils.merge_datasets(zillow_df, census_df, restaurant_df)
        
        # Save merged dataset
        merged_file = f"{Config.RESULTS_DIR}/merged_analysis.csv"
        merged_df.to_csv(merged_file, index=False)
        logger.info(f"ğŸ’¾ Saved merged dataset: {merged_file}")
        
        # Step 5: Visualizations
        logger.info("\nğŸ“Š STEP 5: Creating Visualizations")
        logger.info("-" * 40)
        
        # Filter for cities with complete data
        complete_data = merged_df.dropna(subset=['restaurant_count', 'zhvi_latest'])
        
        if len(complete_data) > 0:
            # Property value ranking
            if not complete_data.empty:
                analysis_utils.create_ranking_plot(
                    complete_data, 'zhvi_latest', 'City',
                    'Bay Area Cities by Property Value (ZHVI)',
                    'Median Home Value ($)',
                    top_n=min(15, len(complete_data)),
                    save_path=f"{Config.RESULTS_DIR}/property_value_ranking.png"
                )
            
            # Restaurant count ranking
            if not complete_data.empty:
                analysis_utils.create_ranking_plot(
                    complete_data, 'restaurant_count', 'City',
                    'Bay Area Cities by Restaurant Count',
                    'Number of Restaurants',
                    top_n=min(15, len(complete_data)),
                    save_path=f"{Config.RESULTS_DIR}/restaurant_count_ranking.png"
                )
            
            # Scatter plot: Property value vs Restaurant count
            if len(complete_data) > 1:
                analysis_utils.create_scatter_plot(
                    complete_data, 'zhvi_latest', 'restaurant_count',
                    'Property Value vs Restaurant Count',
                    'Median Home Value ($)', 'Number of Restaurants',
                    color_col='population',
                    save_path=f"{Config.RESULTS_DIR}/value_vs_restaurants_scatter.png"
                )
            
            # Under-served areas analysis
            if 'restaurants_per_billion_val' in complete_data.columns:
                underserved = analysis_utils.create_summary_table(
                    complete_data, 'restaurants_per_billion_val',
                    ['City', 'zhvi_latest', 'restaurant_count', 'restaurants_per_billion_val'],
                    'Under-served Wealthy Areas (Fewest Restaurants per $B Property Value)',
                    ascending=True, top_n=10
                )
        
        # Step 6: Generate Insights Report
        logger.info("\nğŸ“„ STEP 6: Generating Insights Report")
        logger.info("-" * 40)
        
        report = analysis_utils.generate_insights_report(
            merged_df, 
            save_path=f"{Config.RESULTS_DIR}/insights_report.md"
        )
        
        # Print summary
        logger.info("\nâœ… ANALYSIS COMPLETE!")
        logger.info("=" * 60)
        logger.info(f"ğŸ“ Results saved in: {Config.RESULTS_DIR}/")
        logger.info(f"ğŸ—ºï¸ Maps saved in: {Config.MAPS_DIR}/")
        logger.info(f"ğŸ“Š Visualizations: {Config.RESULTS_DIR}/*.png")
        logger.info(f"ğŸ“„ Full report: {Config.RESULTS_DIR}/insights_report.md")
        
        # Show quick preview of results
        if not merged_df.empty:
            logger.info(f"\nğŸ“‹ Quick Preview ({len(merged_df)} cities analyzed):")
            preview_cols = ['City', 'zhvi_latest', 'restaurant_count']
            available_cols = [col for col in preview_cols if col in merged_df.columns]
            if available_cols:
                print(merged_df[available_cols].head(10).to_string(index=False))
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ Analysis interrupted by user")
    except Exception as e:
        logger.error(f"âŒ Error during analysis: {e}")
        logger.exception("Full error traceback:")
    finally:
        logger.info(f"\nğŸ• Analysis completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def run_quick_test():
    """Run a quick test with minimal data"""
    logger.info("ğŸ§ª Running quick test mode...")
    
    Config.create_directories()
    data_collector = DataCollector()
    restaurant_analyzer = RestaurantAnalyzer()
    
    # Test single city
    test_city = "Atherton"
    logger.info(f"Testing restaurant analysis for {test_city}")
    
    restaurants, center = restaurant_analyzer.get_restaurants_within_radius(test_city)
    logger.info(f"Found {len(restaurants)} restaurants")
    
    if restaurants and center[0] is not None:
        map_obj = restaurant_analyzer.create_restaurant_map(test_city, restaurants, center)
        if map_obj:
            test_file = f"{Config.MAPS_DIR}/test_map.html"
            map_obj.save(test_file)
            logger.info(f"Test map saved: {test_file}")


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Forks & Fortunes: Analyze restaurant density vs wealth in Bay Area cities',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main.py                           # Full analysis of all cities
  python main.py --mode test               # Quick test with 3 cities
  python main.py --mode tier --tier ultra_wealthy    # Analyze only ultra-wealthy cities
  python main.py --mode tier --tier high_wealth      # Analyze only high-wealth cities
  python main.py --quick-test              # Single city map test
        """
    )
    
    parser.add_argument(
        '--mode', 
        choices=['full', 'test', 'tier'], 
        default='full',
        help='Analysis mode: full (all cities), test (3 cities), or tier (specific wealth tier)'
    )
    
    parser.add_argument(
        '--tier',
        choices=['ultra_wealthy', 'high_wealth', 'upper_middle', 'mid_tier', 'urban'],
        help='Wealth tier to analyze (only used with --mode tier)'
    )
    
    parser.add_argument(
        '--quick-test',
        action='store_true',
        help='Run quick single-city test (generates test map)'
    )
    
    parser.add_argument(
        '--list-cities',
        action='store_true',
        help='List all available cities and tiers'
    )
    
    return parser.parse_args()


def list_cities():
    """List all available cities organized by wealth tier"""
    print("\nğŸ™ï¸ Available Cities by Wealth Tier:")
    print("=" * 50)
    
    for tier_name, cities in Config.WEALTH_TIERS.items():
        print(f"\nğŸ’° {tier_name.replace('_', ' ').title()} ({len(cities)} cities):")
        for city in cities:
            print(f"  - {city}")
    
    print(f"\nğŸ“Š Total cities available: {len(Config.CITIES_TO_ANALYZE)}")
    print(f"ğŸ§ª Test cities: {', '.join(Config.TEST_CITIES)}")


if __name__ == "__main__":
    args = parse_arguments()
    
    if args.quick_test:
        run_quick_test()
    elif args.list_cities:
        list_cities()
    elif args.mode == 'tier' and not args.tier:
        print("âŒ Error: --tier argument required when using --mode tier")
        print("Available tiers: ultra_wealthy, high_wealth, upper_middle, mid_tier, urban")
        sys.exit(1)
    else:
        main(mode=args.mode, wealth_tier=args.tier)
